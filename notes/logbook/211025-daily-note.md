#meeting
# Daily Note

25 October 2021

## Meeting with Rich

- NaN issue with classification 
	- Underflow in sigmoid function
	- Look up "log sum exp" trick
	- [ ] Ask Wessel about this plus loading models

- Performance benchmark
	- Use same set of 64 tasks to test models over time
		- Compute average loss and the variance
		- [ ] Ask Wessel how to "seed" the GP synthetic data
	- Pick out three or so tasks that have different characteristics:
		- Sparse regression context points
		- Sparse classification context points
		- *Include loss for these specific tasks as well*
	- Compute epoch zero as well

- Later, consider coupling mechanism
	- Coin toss on threshold
	- Multi-output GP: prior on regression function, sigmoid on classification dataset
		- Ours is a sub-set of this case, the regression function is identical and the classification data is generated by a "hard" decision boundary

- Later, consider sampling from different kernels
	- Say a uniform distribution over 1,2,3 -> EQ, matern, periodic and generate a single task so that the neural process must learn to adapt

- Meeting with Ana and Mark next week
	- [ ] Read climate downscaling paper